{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-TensorFlow.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkgarapa/github-example/blob/master/CNN_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc0ElMm3SVQg",
        "colab_type": "text"
      },
      "source": [
        "#Intro to CNN using TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOaUS8CLSg3K",
        "colab_type": "text"
      },
      "source": [
        "## Basics of Neural Networks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszeMv8UYoEQ",
        "colab_type": "text"
      },
      "source": [
        "### Activation Functions:\n",
        "1. Perceptrons.\n",
        "2. Sigmoid\n",
        "3. TanH\n",
        "4. ReLU\n",
        "5. Others.\n",
        "\n",
        "###A Neural Network:\n",
        "1. Input Layer.\n",
        "2. Hidden Layers.\n",
        "3. Output Layers.\n",
        "4. More Layers --> More Abstraction\n",
        "\n",
        "### To Learn some measurment of error. we use a Cost/Loss function.\n",
        "1. Quadratic.\n",
        "2. Cross-Entropy.\n",
        "\n",
        "<b>\n",
        "Once we have the measurement of error, we need to minimize it by choosing the correct weight and bias value. \n",
        "\n",
        "we use gradient descent to find the optimal values.\n",
        "\n",
        "We can backpropagate the gradient descent through multiple layers, from the output layer back to the input layer.\n",
        "\n",
        "we also know of Dense layers and Softmax layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXmy6E6nWqjX",
        "colab_type": "text"
      },
      "source": [
        "<b> Second order Behavior of gradient descent allows us to adjust our learning rate based of the rate of descent.  \n",
        "\n",
        "faster rates in the begining and slowing it to down at the end.\n",
        "\n",
        "Different methods to doing this second order descent.\n",
        "1. AdaGrad.\n",
        "2. RMS Prop.\n",
        "3. Adam\n",
        "\n",
        "The basic idea of the second order behavior of gradient descent is:\n",
        "\n",
        "1. This allows us to start with larger steps and then eventually go to smaller step sizes.\n",
        "2. Adam allows this change to happen automatically. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L4uoxTAX7E2",
        "colab_type": "text"
      },
      "source": [
        "## Unstable/Vanishing Gradient.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgUv_ofjboKG",
        "colab_type": "text"
      },
      "source": [
        "1. As you increase trhe number of layers in a network, the layers towards the input will be affected less by the error calculation occurring at the output as you go backwards through the network.\n",
        "2. Initialization and Normalization will help us mitigate these issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbVfW6KTZRCE",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4N96-QS9bheh"
      },
      "source": [
        " 1. With potentially hundreds of parameters in a deep learning neural network, the possibility of overfitting is very high!\n",
        "\n",
        " 2. There are few ways to mitigate this issue.\n",
        " \n",
        "  Statistical methods like \n",
        " L1/L2 Reguralization:\n",
        "      * Adds a penalty for larger weights in the model.\n",
        "      * Not unique to neural networks.\n",
        "   \n",
        "   Dropout:\n",
        "      * Unique to neural networks.\n",
        "      * Remove neurons during training randomly.\n",
        "      * Network doesn't  over rely on any particular neuron.\n",
        "\n",
        "    Expanding Data:\n",
        "      * Artificially expand data by adding noise, tilting images, adding low white noise  to sound data, etc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhjLQXLDhClm",
        "colab_type": "text"
      },
      "source": [
        "## Basic Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2hODJRohkpY",
        "colab_type": "text"
      },
      "source": [
        "* Before we dive into using CNN on the MNIST data set we'll use a more basic Softmax Reggression Approach.\n",
        "* A Softmax Regression returns a list of values between 0 and 1 that add up to one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz-lfCukiOLw",
        "colab_type": "text"
      },
      "source": [
        "# MSIT Basic Approach (Softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbd7gnzniUiR",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9TkfwCHSPvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hagNJIlipimP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6jm8mJNpou1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pndjTrRkpyKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8eIMJtYqVq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist.train.images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tPpKZxaqbx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist.train.num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZMlifpQqe0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist.test.num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4gO8HRgqgrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni3Um5KBqyNH",
        "colab_type": "text"
      },
      "source": [
        "the 55000 represent the number of images and 784 pixels ( 28 X 28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOV5dj2cqwGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_image = mnist.train.images[1].reshape(28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpr0hrl6q_12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(single_image, cmap = 'gist_gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjjaFH-vrItF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(single_image.min())\n",
        "print(single_image.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z31zBEG9rSpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_image.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQ2ITJprT35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEYkwytLr1y1",
        "colab_type": "text"
      },
      "source": [
        "# Model Building\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzfH8plssKxf",
        "colab_type": "text"
      },
      "source": [
        "* Placeholders\n",
        "* Variables\n",
        "* Create graph operayions\n",
        "* Loss Functions\n",
        "* Optimizer.\n",
        "* Create Session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJ9H_2ZsIf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Placeholders\n",
        "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
        "\n",
        "# Variables\n",
        "W = tf.Variable(tf.zeros([784,10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "#Create Graph operation\n",
        "y = tf.matmul(x,W)+b\n",
        "\n",
        "# Loss Function\n",
        "y_true = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits = y))\n",
        "\n",
        "#Optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
        "train = optimizer.minimize(cross_entropy)\n",
        "\n",
        "#Create session\n",
        "init = tf.global_variables_initializer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SR10j-uude4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "  sess.run(init)\n",
        "\n",
        "  for step in range(1000):\n",
        "\n",
        "    batch_x, batch_y = mnist.train.next_batch(100)\n",
        "\n",
        "    sess.run(train, feed_dict = {x:batch_x,y_true:batch_y})\n",
        "\n",
        "#Evaluate the Model\n",
        "  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_true,1))\n",
        "\n",
        "# [True,False,True...] --> [1,0,1...]\n",
        "  acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# interpretation of the last two lines code above:\n",
        "# Predicted [3,4] true[3,9]\n",
        "# [True, False]\n",
        "# [1.0, 0.0]\n",
        "# 0.5 ---avg of the above line\n",
        "\n",
        "  print(sess.run(acc, feed_dict={x:mnist.test.images, y_true:mnist.test.labels}))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHUHCnt2ueSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
